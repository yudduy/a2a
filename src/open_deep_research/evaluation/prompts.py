"""Comprehensive evaluation prompts for LLM-based research report assessment."""

class EvaluationPrompts:
    """Collection of specialized prompts for evaluating sequential multi-agent research reports."""

    SINGLE_REPORT_EVALUATION = """You are an expert research analyst tasked with evaluating the quality of a research report generated by a sequential multi-agent system.

The report was created using the "{sequence_name}" agent sequence for the research topic: "{research_topic}"

Your task is to provide a comprehensive evaluation across five key criteria, each scored on a 0-10 scale:

## EVALUATION CRITERIA:

### 1. COMPLETENESS (0-10)
- Coverage of the research topic breadth and scope
- Inclusion of all major aspects and dimensions of the topic  
- Thoroughness in addressing the research question
- No significant gaps or omissions in content

### 2. DEPTH (0-10) 
- Level of analytical rigor and investigation
- Quality of insights and analysis
- Evidence of deep understanding vs. surface-level treatment
- Sophistication of arguments and reasoning

### 3. COHERENCE (0-10)
- How well insights build on each other sequentially
- Logical flow and structure of the report
- Clear connections between different sections/findings
- Consistency in argumentation and narrative

### 4. INNOVATION (0-10)
- Novel insights and unique perspectives
- Creative approaches to analysis
- Original thinking beyond standard treatments
- Surprising or non-obvious connections and findings

### 5. ACTIONABILITY (0-10)
- Practical value of recommendations
- Clear next steps and implementation guidance
- Relevance to real-world decision making
- Specificity and feasibility of suggested actions

## SCORING GUIDELINES:
- 0-2: Poor/Inadequate - Major deficiencies, does not meet basic requirements
- 3-4: Below Average - Some deficiencies, meets minimal requirements
- 5-6: Average - Meets standard expectations with minor gaps
- 7-8: Good - Exceeds expectations in most areas
- 9-10: Excellent - Outstanding performance, best-in-class quality

## YOUR EVALUATION TASK:

For each criterion, provide:
1. **Score (0-10)**: Your numerical assessment
2. **Reasoning**: Detailed justification for the score (2-3 sentences minimum)
3. **Strengths**: Specific examples of what the report does well in this area
4. **Weaknesses**: Specific areas for improvement with examples
5. **Evidence Examples**: Direct quotes or references from the report supporting your assessment

After individual criteria evaluation:
- Calculate an **overall weighted score (0-100)** using these weights:
  - Completeness: 25%
  - Depth: 25% 
  - Coherence: 20%
  - Innovation: 15%
  - Actionability: 15%

- Provide an **executive summary** (3-4 sentences) of the report's overall quality
- List the **top 3-5 key strengths** of the report
- List the **top 3-5 key weaknesses** needing improvement
- Assess the **recommendation quality** and practical value

## RESEARCH REPORT TO EVALUATE:

{report_content}

Please provide a thorough, objective evaluation that will help users understand the strengths and limitations of this sequence-generated research report."""

    COMPARATIVE_ANALYSIS = """You are an expert research analyst conducting a comparative analysis of multiple research reports generated by different sequential multi-agent systems.

All reports address the same research topic: "{research_topic}"

The reports were generated using these agent sequences:
{sequence_names}

Your task is to conduct a comprehensive comparative analysis to determine which sequence strategy produced the best overall research output.

## INDIVIDUAL REPORT EVALUATIONS:
{individual_evaluations}

## COMPARATIVE ANALYSIS REQUIREMENTS:

### 1. OVERALL RANKING
- Rank all reports from best to worst based on overall weighted scores
- Identify the winning sequence and provide clear reasoning
- Calculate performance gaps between sequences

### 2. CRITERIA-SPECIFIC ANALYSIS  
For each evaluation criterion (Completeness, Depth, Coherence, Innovation, Actionability):
- Identify which sequence performed best for that specific criterion
- Analyze patterns in sequence performance across criteria
- Explain why certain sequences excel in specific areas

### 3. PAIRWISE COMPARISONS
For each pair of sequences, determine:
- Which sequence is superior and by what margin
- Specific advantages each sequence demonstrates
- Scenarios where each sequence would be preferred
- Detailed reasoning for comparison outcomes

### 4. STRATEGIC INSIGHTS
- Identify common strengths/weakness patterns by sequence type
- Analyze how agent ordering affects research outcomes
- Provide sequence selection guidelines based on research context
- Suggest improvements for underperforming sequences

### 5. PRACTICAL RECOMMENDATIONS
Based on your analysis, provide:
- Clear guidance on when to use each sequence type
- Specific scenarios where each sequence excels
- Improvement recommendations for each sequence
- Best practices for sequential multi-agent research

## EVALUATION CONFIDENCE:
Assess your confidence level (0-1) in this comparative analysis and explain any limitations or uncertainties.

Focus on providing actionable insights that will help users select optimal agent sequences for different types of research challenges."""

    PAIRWISE_COMPARISON = """You are conducting a detailed pairwise comparison between two research reports generated by different sequential multi-agent systems.

**Research Topic:** {research_topic}

**Sequence A:** {sequence_a_name}
**Sequence B:** {sequence_b_name}

## REPORTS TO COMPARE:

### Report A ({sequence_a_name}):
{report_a_content}

### Report B ({sequence_b_name}):
{report_b_content}

## COMPARISON TASK:

### 1. DIRECT COMPARISON
For each evaluation criterion, determine which report is superior:
- **Completeness**: Which report provides more comprehensive coverage?
- **Depth**: Which report demonstrates deeper analysis and insights?
- **Coherence**: Which report has better structure and logical flow?
- **Innovation**: Which report presents more novel perspectives?
- **Actionability**: Which report offers more practical value?

### 2. COMPARATIVE STRENGTHS
Identify specific areas where each report/sequence excels:
- What does Report A do better than Report B?
- What does Report B do better than Report A?
- Provide concrete examples and evidence

### 3. OVERALL WINNER
- Declare the winning report with clear justification
- Calculate the performance margin (score difference)
- Explain the key factors that determined the winner

### 4. USE CASE RECOMMENDATIONS
- Describe scenarios where Sequence A would be preferred
- Describe scenarios where Sequence B would be preferred
- Consider different research contexts and objectives

Provide a thorough, evidence-based comparison that clearly identifies strengths, weaknesses, and the optimal use cases for each sequence approach."""

    CRITERIA_DEEP_DIVE = """You are conducting an in-depth analysis of how different sequential multi-agent approaches perform on a specific evaluation criterion.

**Research Topic:** {research_topic}
**Focus Criterion:** {criterion_name}
**Criterion Definition:** {criterion_definition}

## REPORTS FOR ANALYSIS:
{reports_content}

## DEEP DIVE ANALYSIS REQUIREMENTS:

### 1. CRITERION-SPECIFIC RANKING
- Rank all reports specifically for this criterion
- Identify the clear leader and explain why
- Calculate performance gaps between approaches

### 2. PATTERN ANALYSIS  
- How does agent sequence order affect performance on this criterion?
- Which types of agents (theory-first, market-first, etc.) excel here?
- Are there consistent patterns across different sequence strategies?

### 3. SUCCESS FACTORS
- What specific elements make a report excel in this criterion?
- Which research approaches are most effective for this criterion?
- How do different agent handoffs impact performance?

### 4. FAILURE MODES
- What causes reports to perform poorly on this criterion?
- Which sequence strategies struggle with this aspect?
- What are common pitfalls to avoid?

### 5. OPTIMIZATION RECOMMENDATIONS
For each sequence approach, provide specific suggestions to improve performance on this criterion:
- What changes to agent ordering would help?
- Which additional analysis steps would be beneficial?
- How can handoff context be optimized for this criterion?

Focus on providing actionable insights for optimizing sequential multi-agent systems to excel on this specific evaluation dimension."""

    EXECUTIVE_SUMMARY = """Based on your comprehensive evaluation of multiple research reports from different sequential multi-agent systems, provide a concise executive summary for decision-makers.

**Research Topic:** {research_topic}
**Sequences Evaluated:** {sequence_names}

## EXECUTIVE SUMMARY REQUIREMENTS:

### 1. KEY FINDINGS (2-3 sentences)
- Which sequence performed best overall and why
- Most significant performance differences observed
- Primary factors determining success

### 2. STRATEGIC RECOMMENDATIONS (3-4 bullet points)
- When to use the top-performing sequence
- Alternative sequences for specific scenarios  
- Key considerations for sequence selection

### 3. PERFORMANCE INSIGHTS (2-3 bullet points)
- Most important strengths of the winning approach
- Critical gaps or limitations to be aware of
- Unexpected findings from the analysis

### 4. IMPLEMENTATION GUIDANCE (2-3 bullet points)
- Practical next steps for adopting the best sequence
- Potential improvements for current approaches
- Success metrics to monitor

Keep the summary concise, actionable, and focused on helping users make informed decisions about sequential multi-agent research strategies."""

    @classmethod
    def get_single_report_prompt(cls, sequence_name: str, research_topic: str, report_content: str) -> str:
        """Get formatted prompt for evaluating a single research report."""
        return cls.SINGLE_REPORT_EVALUATION.format(
            sequence_name=sequence_name,
            research_topic=research_topic,
            report_content=report_content
        )
    
    @classmethod  
    def get_comparative_analysis_prompt(cls, research_topic: str, sequence_names: List[str], 
                                      individual_evaluations: str) -> str:
        """Get formatted prompt for comparative analysis of multiple reports."""
        return cls.COMPARATIVE_ANALYSIS.format(
            research_topic=research_topic,
            sequence_names=", ".join(sequence_names),
            individual_evaluations=individual_evaluations
        )
    
    @classmethod
    def get_pairwise_comparison_prompt(cls, research_topic: str, sequence_a_name: str, 
                                     sequence_b_name: str, report_a_content: str, 
                                     report_b_content: str) -> str:
        """Get formatted prompt for pairwise comparison between two reports."""
        return cls.PAIRWISE_COMPARISON.format(
            research_topic=research_topic,
            sequence_a_name=sequence_a_name,
            sequence_b_name=sequence_b_name,
            report_a_content=report_a_content,
            report_b_content=report_b_content
        )
    
    @classmethod
    def get_criteria_deep_dive_prompt(cls, research_topic: str, criterion_name: str,
                                    criterion_definition: str, reports_content: str) -> str:
        """Get formatted prompt for deep dive analysis of a specific criterion."""
        return cls.CRITERIA_DEEP_DIVE.format(
            research_topic=research_topic,
            criterion_name=criterion_name,
            criterion_definition=criterion_definition,
            reports_content=reports_content
        )
    
    @classmethod
    def get_executive_summary_prompt(cls, research_topic: str, sequence_names: List[str]) -> str:
        """Get formatted prompt for executive summary generation."""
        return cls.EXECUTIVE_SUMMARY.format(
            research_topic=research_topic,
            sequence_names=", ".join(sequence_names)
        )